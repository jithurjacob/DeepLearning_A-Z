{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"../instructor/Google_Stock_Price_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = training_set.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "# as lstm use sigmoid it is better to scale min max \n",
    "# than standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = training_Set[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_train = training_Set[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with 20 timesteps and t+1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(20, 1258):\n",
    "    X_train.append(training_set_scaled[i-20:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "# /Keras RNN layer expects input in 3 col \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making prections and visualizing the results\n",
    "test_Set = pd.read_csv(\"../instructor/Google_Stock_Price_Test.csv\")\n",
    "real_stock_price = test_Set.iloc[:,1:2].values\n",
    "# getting the prediction of stock price of 2017\n",
    "inputs = real_stock_price\n",
    "inputs = sc.transform(inputs)\n",
    "inputs = np.reshape(inputs, (20,1,1))\n",
    "\n",
    "def visualize(regressor):\n",
    "    predicted_stock_price = regressor.predict(inputs)\n",
    "    predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "    # visualizing the results\n",
    "    plt.plot(real_stock_price, color='red',label='Real Google Stock Price')\n",
    "    plt.plot(predicted_stock_price, color='blue',label='Predicted Google Stock Price')\n",
    "    plt.title(\"Google Stock Price Prediction\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_stock_price_train = pd.read_csv(\"../instructor/Google_Stock_Price_Train.csv\")\n",
    "real_stock_price_train = real_stock_price_train.iloc[:,1:2].values\n",
    "def get_rmse(regressor):\n",
    "    predicted_stock_price_train = regressor.predict(X_train)\n",
    "    predicted_stock_price_train = sc.inverse_transform(predicted_stock_price_train)\n",
    "    plt.plot(real_stock_price_train, color='red',label='Real Google Stock Price')\n",
    "    plt.plot(predicted_stock_price_train, color='blue',label='Predicted Google Stock Price')\n",
    "    plt.title(\"Google Stock Price Prediction\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return  math.sqrt(mean_squared_error(real_stock_price,predicted_stock_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1238/1238 [==============================] - 1s - loss: 0.3002     \n",
      "Epoch 2/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.2507     \n",
      "Epoch 3/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.2081     \n",
      "Epoch 4/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.1707     \n",
      "Epoch 5/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.1384     \n",
      "Epoch 6/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.1118     \n",
      "Epoch 7/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0911     \n",
      "Epoch 8/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0773     \n",
      "Epoch 9/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0698     \n",
      "Epoch 10/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0660     \n",
      "Epoch 11/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0636     \n",
      "Epoch 12/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0619     \n",
      "Epoch 13/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0604     \n",
      "Epoch 14/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0590     \n",
      "Epoch 15/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0577     \n",
      "Epoch 16/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0564     \n",
      "Epoch 17/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0550     \n",
      "Epoch 18/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0536     \n",
      "Epoch 19/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0522     \n",
      "Epoch 20/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0508     \n",
      "Epoch 21/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0493     \n",
      "Epoch 22/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0478     \n",
      "Epoch 23/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0462     \n",
      "Epoch 24/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0447     \n",
      "Epoch 25/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0431     \n",
      "Epoch 26/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0415     \n",
      "Epoch 27/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0399     \n",
      "Epoch 28/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0382     \n",
      "Epoch 29/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0366     \n",
      "Epoch 30/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0350     \n",
      "Epoch 31/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0334     \n",
      "Epoch 32/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0318     \n",
      "Epoch 33/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0302     \n",
      "Epoch 34/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0287     \n",
      "Epoch 35/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0271     \n",
      "Epoch 36/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0257     \n",
      "Epoch 37/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0242     \n",
      "Epoch 38/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0228     \n",
      "Epoch 39/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0215     \n",
      "Epoch 40/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0202     \n",
      "Epoch 41/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0189     \n",
      "Epoch 42/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0177     \n",
      "Epoch 43/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0166     \n",
      "Epoch 44/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0155     \n",
      "Epoch 45/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0144     \n",
      "Epoch 46/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0135     \n",
      "Epoch 47/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0125     \n",
      "Epoch 48/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0117     \n",
      "Epoch 49/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0108     \n",
      "Epoch 50/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0101     \n",
      "Epoch 51/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0093     \n",
      "Epoch 52/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0087     \n",
      "Epoch 53/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0080     \n",
      "Epoch 54/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0075     \n",
      "Epoch 55/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0069     \n",
      "Epoch 56/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0064     \n",
      "Epoch 57/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 58/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 59/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 60/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 61/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 62/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 63/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 64/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 65/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0034     \n",
      "Epoch 66/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0032     \n",
      "Epoch 67/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0030     \n",
      "Epoch 68/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0028     \n",
      "Epoch 69/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0026     \n",
      "Epoch 70/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0025     \n",
      "Epoch 71/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0024     \n",
      "Epoch 72/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0022     \n",
      "Epoch 73/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0021     \n",
      "Epoch 74/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0020     \n",
      "Epoch 75/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0020     \n",
      "Epoch 76/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0019     \n",
      "Epoch 77/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0018     \n",
      "Epoch 78/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0017     \n",
      "Epoch 79/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0017     \n",
      "Epoch 80/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0016     \n",
      "Epoch 81/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0016     \n",
      "Epoch 82/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0015     \n",
      "Epoch 83/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0015     \n",
      "Epoch 84/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0014     \n",
      "Epoch 85/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0014     \n",
      "Epoch 86/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0014     \n",
      "Epoch 87/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0013     \n",
      "Epoch 88/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0013     \n",
      "Epoch 89/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0013     \n",
      "Epoch 90/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0012     \n",
      "Epoch 91/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0012     \n",
      "Epoch 92/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0012     \n",
      "Epoch 93/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0012     \n",
      "Epoch 94/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0011     \n",
      "Epoch 95/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0011     \n",
      "Epoch 96/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0011     \n",
      "Epoch 97/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0011     \n",
      "Epoch 98/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0011     \n",
      "Epoch 99/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 101/200\n",
      "1238/1238 [==============================] - 0s - loss: 0.0010         \n",
      "Epoch 102/200\n",
      "1238/1238 [==============================] - 0s - loss: 9.8223e-04     \n",
      "Epoch 103/200\n",
      "1238/1238 [==============================] - 0s - loss: 9.6630e-04     \n",
      "Epoch 104/200\n",
      "1238/1238 [==============================] - 0s - loss: 9.4853e-04     \n",
      "Epoch 105/200\n",
      "1238/1238 [==============================] - 0s - loss: 9.3105e-04     \n",
      "Epoch 106/200\n",
      "1238/1238 [==============================] - 0s - loss: 9.1366e-04     \n",
      "Epoch 107/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.9784e-04     \n",
      "Epoch 108/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.8171e-04     \n",
      "Epoch 109/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.6834e-04     \n",
      "Epoch 110/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.4902e-04     \n",
      "Epoch 111/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.3260e-04     \n",
      "Epoch 112/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.2135e-04     \n",
      "Epoch 113/200\n",
      "1238/1238 [==============================] - 0s - loss: 8.0891e-04     \n",
      "Epoch 114/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.9651e-04     \n",
      "Epoch 115/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.7767e-04     \n",
      "Epoch 116/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.6229e-04     \n",
      "Epoch 117/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.5101e-04     \n",
      "Epoch 118/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.3623e-04     \n",
      "Epoch 119/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.2362e-04     \n",
      "Epoch 120/200\n",
      "1238/1238 [==============================] - 0s - loss: 7.1265e-04     \n",
      "Epoch 121/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.9898e-04     \n",
      "Epoch 122/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.8837e-04     \n",
      "Epoch 123/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.7567e-04     \n",
      "Epoch 124/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.6774e-04     \n",
      "Epoch 125/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.5423e-04     \n",
      "Epoch 126/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.4320e-04     \n",
      "Epoch 127/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.3559e-04     \n",
      "Epoch 128/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.2540e-04     \n",
      "Epoch 129/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.1309e-04     \n",
      "Epoch 130/200\n",
      "1238/1238 [==============================] - 0s - loss: 6.0457e-04     \n",
      "Epoch 131/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.9627e-04     \n",
      "Epoch 132/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.8795e-04     \n",
      "Epoch 133/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.7698e-04     \n",
      "Epoch 134/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.6757e-04     \n",
      "Epoch 135/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.5918e-04     \n",
      "Epoch 136/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.5347e-04     \n",
      "Epoch 137/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.4549e-04     \n",
      "Epoch 138/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.3603e-04     \n",
      "Epoch 139/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.2798e-04     \n",
      "Epoch 140/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.2185e-04     \n",
      "Epoch 141/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.1481e-04     \n",
      "Epoch 142/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.0956e-04     \n",
      "Epoch 143/200\n",
      "1238/1238 [==============================] - 0s - loss: 5.0145e-04     \n",
      "Epoch 144/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.9378e-04     \n",
      "Epoch 145/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.8800e-04     \n",
      "Epoch 146/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.8252e-04     \n",
      "Epoch 147/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.7520e-04     \n",
      "Epoch 148/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.6843e-04     \n",
      "Epoch 149/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.6247e-04     \n",
      "Epoch 150/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.5737e-04     \n",
      "Epoch 151/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.5635e-04     \n",
      "Epoch 152/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.4859e-04     \n",
      "Epoch 153/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.4115e-04     \n",
      "Epoch 154/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.3884e-04     \n",
      "Epoch 155/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.3678e-04     \n",
      "Epoch 156/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.3032e-04     \n",
      "Epoch 157/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.2494e-04     \n",
      "Epoch 158/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.1888e-04     \n",
      "Epoch 159/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.1536e-04     \n",
      "Epoch 160/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.1102e-04     \n",
      "Epoch 161/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.0750e-04     \n",
      "Epoch 162/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.0595e-04     \n",
      "Epoch 163/200\n",
      "1238/1238 [==============================] - 0s - loss: 4.0105e-04     \n",
      "Epoch 164/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.9524e-04     \n",
      "Epoch 165/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.9241e-04     \n",
      "Epoch 166/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.9168e-04     \n",
      "Epoch 167/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.8634e-04     \n",
      "Epoch 168/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.8277e-04     \n",
      "Epoch 169/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.7922e-04     \n",
      "Epoch 170/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.7680e-04     \n",
      "Epoch 171/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.7428e-04     \n",
      "Epoch 172/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.7246e-04     \n",
      "Epoch 173/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.7145e-04     \n",
      "Epoch 174/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.6868e-04     \n",
      "Epoch 175/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.6775e-04     \n",
      "Epoch 176/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.6102e-04     \n",
      "Epoch 177/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.5796e-04     \n",
      "Epoch 178/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.5307e-04     \n",
      "Epoch 179/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.5394e-04     \n",
      "Epoch 180/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.5207e-04     \n",
      "Epoch 181/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.4932e-04     \n",
      "Epoch 182/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.4756e-04     \n",
      "Epoch 183/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.4726e-04     \n",
      "Epoch 184/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.4397e-04     \n",
      "Epoch 185/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.4217e-04     \n",
      "Epoch 186/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3971e-04     \n",
      "Epoch 187/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3790e-04     \n",
      "Epoch 188/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3577e-04     \n",
      "Epoch 189/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3746e-04     \n",
      "Epoch 190/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3391e-04     \n",
      "Epoch 191/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3051e-04     \n",
      "Epoch 192/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.3255e-04     \n",
      "Epoch 193/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2904e-04     \n",
      "Epoch 194/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2711e-04     \n",
      "Epoch 195/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2588e-04     \n",
      "Epoch 196/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2522e-04     \n",
      "Epoch 197/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2258e-04     \n",
      "Epoch 198/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.2094e-04     \n",
      "Epoch 199/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.1873e-04     \n",
      "Epoch 200/200\n",
      "1238/1238 [==============================] - 0s - loss: 3.1897e-04     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90218d1d30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1 = Sequential()\n",
    "# input layer and lstm layer\n",
    "# 4 memory cells\n",
    "regressor1.add(LSTM(units = 1, activation='sigmoid',input_shape=(None,1)))\n",
    "# adding output layer\n",
    "# 1 output ie, price at time t+1\n",
    "regressor1.add(Dense(units=1))\n",
    "# compiling the RNN\n",
    "regressor1.compile(optimizer='adam',loss='mean_squared_error')\n",
    "#fitting the trainingdata\n",
    "regressor1.fit(X_train,y_train,batch_size=32,epochs=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9020363f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price for February 1st 2012 - January 31st 2017\n",
    "dataset_test = pd.read_csv('../instructor/Google_Stock_Price_Test.csv')\n",
    "test_set = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price = np.concatenate((training_set[0:1258], test_set), axis = 0)\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "scaled_real_stock_price = sc.fit_transform(real_stock_price)\n",
    "inputs = []\n",
    "for i in range(1258, 1278):\n",
    "    inputs.append(scaled_real_stock_price[i-20:i, 0])\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.reshape(inputs, (inputs.shape[0], inputs.shape[1], 1))\n",
    "predicted_stock_price = regressor1.predict(inputs)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price[1258:], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1238/1238 [==============================] - 5s - loss: 0.1269     \n",
      "Epoch 2/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0307     \n",
      "Epoch 3/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0040     \n",
      "Epoch 4/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0026     \n",
      "Epoch 5/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0024     \n",
      "Epoch 6/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0022     \n",
      "Epoch 7/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0023     \n",
      "Epoch 8/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0022     \n",
      "Epoch 9/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0022     \n",
      "Epoch 10/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 11/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0022     \n",
      "Epoch 12/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 13/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 14/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 15/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 16/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 17/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 18/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 19/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 20/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 21/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 22/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0021     \n",
      "Epoch 23/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 24/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 25/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 26/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 27/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 28/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0018     \n",
      "Epoch 29/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0020     \n",
      "Epoch 30/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 31/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 32/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0018     \n",
      "Epoch 33/100\n",
      "1238/1238 [==============================] - 2s - loss: 0.0019     \n",
      "Epoch 34/100\n",
      "  64/1238 [>.............................] - ETA: 2s - loss: 0.0010"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 3, return_sequences = True, input_shape = (None, 1)))\n",
    "\n",
    "# Adding a second LSTM layer\n",
    "regressor.add(LSTM(units = 3, return_sequences = True))\n",
    "\n",
    "# Adding a third LSTM layer\n",
    "regressor.add(LSTM(units = 3, return_sequences = True))\n",
    "\n",
    "# Adding a fourth LSTM layer\n",
    "regressor.add(LSTM(units = 3))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
    "\n",
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price for February 1st 2012 - January 31st 2017\n",
    "dataset_test = pd.read_csv('../instructor/Google_Stock_Price_Test.csv')\n",
    "test_set = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price = np.concatenate((training_set[0:1258], test_set), axis = 0)\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "scaled_real_stock_price = sc.fit_transform(real_stock_price)\n",
    "inputs = []\n",
    "for i in range(1258, 1278):\n",
    "    inputs.append(scaled_real_stock_price[i-60:i, 0])\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.reshape(inputs, (inputs.shape[0], inputs.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(inputs)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price[1258:], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
